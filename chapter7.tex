\chapter{Results and Future works}
\label{cha:futureworks}

\section{Conclusion}

In the end, the robot, whether real o simulated, is able to \textbf{navigate} the environment, detect \textbf{obstacles} and take actions to \textbf{avoid} them. Moreover, the robot can move \textbf{indipendently} from one room to another, without having to manually control it (setting the destination). When the drones project is also completed and tested, it will be possible to \textbf{combine} everything together and have a \textbf{complete system} as originally designated.

\section{Further improvements}

Here is a possible list of missing or incomplete features that can be implemented or improved in the future:

\begin{itemize}

\item Currently, of three \textit{shelfino} robots, two are working, and only one is \textbf{accessible} through the network, necessary to configure it for the current project: although it was supposed to be a multi-robot system, it was tested with only one, for obvious reasons. Once this issue is solved, a multi-robot test could be performed.

\item Due to \textbf{asynchronous} development of each project, on the planning part was assumed that only \acrshort{uavs} are able to \textbf{take photos}, although it could also be done with \acrshort{ugvs}: the implementation would be quite straightforward. At this time, \acrshort{ugvs} are only moving around, without a surveillance task, if you do not consider carrying \acrshort{uavs} on its top.

\item From the specific actions designed for \acrshort{ugvs}, only \code{movement} and \code{move\_with\_uav} have been implemented, as opposed to \code{battery\_managment} and \code{charge} operations, because there is \textbf{no way} to interface with the batteries and auto-charging them is not possible since a \textbf{missing infrastructure} is needed; in other words, such actions, are currently only possible manually (with voltmeter and cables).

\item An interesting feature that could be supported, as soon as fully implemented in the planning system, is \textbf{live positioning}: in this way you could have a \textbf{real-time position feedback} even in the web interface; the only change is to return the position of the robot\footnote{Obtained from the pose server, described in \autoref{sub:pose}} along with the percentage completion of the current task.

\item Talking about the navigation part, the obstacle avoidance could be enhanced, especially in the case of dynamic obstacles, because the robot sometimes takes some time to understand what is happening, and may end up colliding with them. A possible solution would be to increase the minimum distance that should be kept between the robot and the unexpected obstacle, with also some recovery action, such as going back a little and replanning the path. A problem could also be the \code{ros1\_bridge} that adds some delay in the exchange of messages between \acrshort{ros}1 and \acrshort{ros}2, ending up receiving lidar data not instantly.

\item Improve the map, creating a custom one for simulation and keeping the current one for the real world. If a better mesh is available, \acrshort{slam} and waypoint extraction in the simulation and in the real world might be the same, and then you would not need to \textbf{switch} between them every time.

\end{itemize}